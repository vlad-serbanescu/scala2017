\section{Implementation}
\label{run}
The implementation of the full data-oriented scheme is done through a library which contains a set of classes and interfaces that have a direct mapping to the ABS language concepts described in Section~\ref{lang}. The library provides an implementation of cooperative scheduling behavior, the suspension and release mechanisms while respecting the logic of synchronous calls. The library provides the solution and the optimizations discussed in Section~\ref{scheme}. The library can be obtained as a maven project and is available online~\footnote{https://github.com/vlad-serbanescu/abs-api-cwi.git (Local Actor branch)} with the compiler ~\footnote{https://github.com/CrispOSS/jabsc  (Scala Writer branch)}.



%A problem that can arise when there are more actors than available threads in the system's executor, some actors may keep processing one message after the other from its queue, and thus keeping the thread it is running on, while some other actors are starving, i.e., not being assigned to any thread.

%\subsection{Suspension and Release Points}
%

\subsection{Actor Implementation}
The library offers an interface \textbf{Actor} containing several methods for implementing the behavior of synchronous (\textit{sendSync}), asynchronous (\textit{send}) method calls and await statements (\textit{await}) from ABS. The \textit{await} statement provided by the library is implemented in such a way that it supports an explicit continuation that can be either generated by the compiler from ABS or used by the programmer directly in Scala using the library.  The library currently supports an implementation of this interface called \textbf{LocalActor} for actors running on the same machine. An important advantage of having a task assigned to each actor and a manually processed queue is that we can start and stop the task depending on the queue state. To avoid keeping the Main Task alive, we make it part of the functionality of sending a message or completing a future to notify the Main Task. This is done by any other actor who sends an invocation to an empty queue and subsequently the Main Task stops when there are no more enabled messages in the queue. 

\par Inside the \textbf{LocalActor} class there is a \textit{messageQueue} defined which holds all the invocations (synchronous or asynchronous) that have been submitted to the actor as tasks. The implementation defines an inner class \textit{MainTask} which is a Java Runnable that corresponds to the task responsible for taking messages from the queue and running them. When the queue is empty, we do not want to make this task busy-wait until a message arrives, and so, upon insertion of a new message into the queue, there is a check whether such a task exists already. This gives rise to some subtle synchronization points. For every actor, we keep a local atomic boolean flag \textit{mainTaskIsRunning}. A first approach looks like in Listing~\ref{basicsync}:  \\ \\

\begin{lstlisting}[float, caption= Basic Synchronization Approach, label=basicsync]
	// inside the task
	class MainTask implements Runnable{
		public void run() ({
				// iterate through queue and take one message and run it
			mainTaskIsRunning.set(false);
	}	}
	
	// when inserting a new message
	messageQueue.add(m);
	if (!mainTaskIsRunning.compareAndSet(false, true)) {
		DeploymentComponent.submit(new MainTask())
	}
\end{lstlisting}
\begin{lstlisting}[caption= Complete Synchronization Approach, label=completesync]
private boolean takeOrDie() {
	synchronized (mainTaskIsRunning) {
		
		// iterate through queue and take one ready message 
		// if it exists set the next message for the main task and then
		return true;
		
		//if the queue if empty or no message is able to run
		mainTaskIsRunning.set(false);
		return false;
}	}
private boolean notRunningThenStart() {
	synchronized (mainTaskIsRunning) {
		return mainTaskIsRunning.compareAndSet(false, true);
}	}

// inside the task
class MainTask implements Runnable{
	
	public void run() {
	while (takeOrDie())
		// proceed to take the next message message and run it	 
}	}

// when inserting a new message
messageQueue.add(m);
if (notRunningThenStart()) {
	DeploymentComponent.submit(new MainTask());
}
\end{lstlisting}

The problem with the code in Listing~\ref{basicsync} is that the check of the queue for emptiness and setting the flag to "false" is not atomic, and in between these two statements, a new message may be inserted into the queue without spawning a new Main Task. To remedy this, in Listing~\ref{completesync}, we introduce a new method that can check the queue for emptiness and set the flag to "false" in a critical section, for example inside a "synchronized" block using the \textit{messageQueue} or \textit{mainTaskIsRunning} as the lock. Additionally, either the insertion into the \textit{messageQueue} or \textit{compareAndSet} of \textit{mainTaskIsRunning} should also use the same lock.  Another problem with this approach above is that, when there are more actors than available threads, there is no fairness policy when assigning a thread to an actor. To remedy this, we could change the while loop to an if statement like in Listing~\ref{fair}: 
\begin{lstlisting}[caption= Fairness Between Actors, label=fair]
class MainTask implements Runnable{
	public void run() {
		if (!takeOrDie())
			return;
		// proceed to take the next message message and run it	 
		DeploymentComponent.submit(this);
	}	
}
\end{lstlisting}



\subsection{Actor System Implementation}

The system executor uses a \textit{newCachedThreadPool} singleton \textit{ExecutorService} that automatically creates and allocates threads to handle the current load of the system. 
An actor may start a new \lstinline"MainTask" (for processing messages in the queue) by  calling the static method \lstinline|submit(new MainTask())|. 
Inside the class there is also support to safely call \lstinline|shutdown()| when all the actors in the application have completed execution. 
Further in this section we explain some details and optimizations implemented in management of actors and their corresponding tasks.

%These latter release points require the system to have a notification mechanism for actors with empty queues and newly enabled messages. 

\paragraph{Eliminating busy waiting.}
%There are two scenarios that (re-)enable actor tasks: 1) when a message is sent to an actor; 2) or, when a future that guards a continuation is completed by another actor. 
%The actor task will stay active as long as there are  messages to execute.
%The second element is the notification mechanism together with a \textit{ConcurrentHashMap} that contains mappings of futures that hold release points on actors in the system.

Cooperative scheduling through release points may suspend the current message run by the actor based on either a particular inner state or future requiring completion on a different actor. We discussed how the Main Task can start or stop based on release points, but it is important to observe how exactly does an actor verify that a release point has completed. Having a task continuously iterate through all suspended messages (busy-waiting) is inefficient. We can separate the messages that are guarded by an incomplete future until that future completes such that the Main Task does not need to check them. Subsequently they can be put in the \textit{messageQueue} once the future guard completes. 
The same procedure cannot be applied for a message whose enabling condition depends on the actor state, as its state can change again, so it always has to be verified before a message is scheduled. We assign this verification to the Main Task that iterates through the queue, and simply stop the task if no message is available after one iteration. If the task does stop, it means that the actor is in a state in which it is unable to execute any of its suspended messages. Therefore, it requires another actor to either send a new invocation that will change its state or the system to send a notification about a future that may release some of its messages and re-enable the Main Task. 
Therefore we maintain a global hash table, mapping every future to the set of actors that are awaiting on its completion. 
Actors that complete a certain future can call the static method \lstinline|releaseAll(f)| (provided at the system level) to notify actors that contain messages suspended on that particular future. 
 
\paragraph{Using JVM Garbage Collection}
Using the approach explained so far in this section, the only extra references we need for the actors are the ones inside the global hash-table required for the notification mechanism for futures. Once the future is completed and notifications are sent, the key is deleted and the actor references become unreachable. Therefore we can leave the entire garbage collection process to the Java Runtime Environment as no other bookkeeping mechanisms are required. This way we do not keep a registry of the actors like the {\ttfamily context} in Scala and Akka.









